{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n",
      "['a1_0', 'a1_1', 'a1_10', 'a1_100', 'a1_101', 'a1_102', 'a1_103', 'a1_104', 'a1_105', 'a1_106', 'a1_107', 'a1_108', 'a1_109', 'a1_11', 'a1_110', 'a1_111', 'a1_112', 'a1_113', 'a1_114', 'a1_115', 'a1_116', 'a1_117', 'a1_118', 'a1_119', 'a1_12', 'a1_120', 'a1_121', 'a1_122', 'a1_123', 'a1_124', 'a1_125', 'a1_126', 'a1_127', 'a1_128', 'a1_129', 'a1_13', 'a1_130', 'a1_131', 'a1_132', 'a1_133', 'a1_134', 'a1_135', 'a1_136', 'a1_137', 'a1_138', 'a1_139', 'a1_14', 'a1_140', 'a1_141', 'a1_142', 'a1_143', 'a1_144', 'a1_145', 'a1_146', 'a1_147', 'a1_148', 'a1_149', 'a1_15', 'a1_150', 'a1_151', 'a1_152', 'a1_153', 'a1_154', 'a1_155', 'a1_156', 'a1_157', 'a1_158', 'a1_159', 'a1_16', 'a1_160', 'a1_161', 'a1_162', 'a1_163', 'a1_164', 'a1_165', 'a1_166', 'a1_167', 'a1_168', 'a1_169', 'a1_17', 'a1_170', 'a1_171', 'a1_172', 'a1_173', 'a1_174', 'a1_175', 'a1_176', 'a1_177', 'a1_178', 'a1_179', 'a1_18', 'a1_180', 'a1_181', 'a1_182', 'a1_183', 'a1_184', 'a1_185', 'a1_186', 'a1_187', 'a1_188', 'a1_189', 'a1_19', 'a1_190', 'a1_191', 'a1_192', 'a1_193', 'a1_194', 'a1_195', 'a1_196', 'a1_197', 'a1_198', 'a1_199', 'a1_2', 'a1_20', 'a1_200', 'a1_201', 'a1_202', 'a1_203', 'a1_204', 'a1_205', 'a1_206', 'a1_207', 'a1_208', 'a1_209', 'a1_21', 'a1_210', 'a1_211', 'a1_212', 'a1_213', 'a1_214', 'a1_215', 'a1_216', 'a1_217', 'a1_218', 'a1_219', 'a1_22', 'a1_220', 'a1_221', 'a1_222', 'a1_223', 'a1_224', 'a1_225', 'a1_226', 'a1_227', 'a1_228', 'a1_229', 'a1_23', 'a1_230', 'a1_231', 'a1_232', 'a1_233', 'a1_234', 'a1_235', 'a1_236', 'a1_237', 'a1_238', 'a1_239', 'a1_24', 'a1_240', 'a1_241', 'a1_242', 'a1_243', 'a1_244', 'a1_245', 'a1_246', 'a1_247', 'a1_248', 'a1_249', 'a1_25', 'a1_250', 'a1_251', 'a1_252', 'a1_253', 'a1_254', 'a1_255', 'a1_256', 'a1_257', 'a1_258', 'a1_259', 'a1_26', 'a1_260', 'a1_261', 'a1_262', 'a1_263', 'a1_264', 'a1_265', 'a1_266', 'a1_267', 'a1_268', 'a1_269', 'a1_27', 'a1_270', 'a1_271', 'a1_272', 'a1_273', 'a1_274', 'a1_275', 'a1_276', 'a1_277', 'a1_278', 'a1_279', 'a1_28', 'a1_280', 'a1_281', 'a1_282', 'a1_283', 'a1_284', 'a1_285', 'a1_286', 'a1_287', 'a1_288', 'a1_289', 'a1_29', 'a1_290', 'a1_291', 'a1_292', 'a1_293', 'a1_294', 'a1_295', 'a1_296', 'a1_297', 'a1_298', 'a1_299', 'a1_3', 'a1_30', 'a1_300', 'a1_301', 'a1_302', 'a1_303', 'a1_304', 'a1_305', 'a1_306', 'a1_307', 'a1_308', 'a1_309', 'a1_31', 'a1_310', 'a1_311', 'a1_312', 'a1_313', 'a1_314', 'a1_315', 'a1_316', 'a1_317', 'a1_318', 'a1_319', 'a1_32', 'a1_320', 'a1_321', 'a1_322', 'a1_323', 'a1_324', 'a1_325', 'a1_326', 'a1_327', 'a1_328', 'a1_329', 'a1_33', 'a1_330', 'a1_331', 'a1_332', 'a1_333', 'a1_334', 'a1_335', 'a1_336', 'a1_337', 'a1_338', 'a1_339', 'a1_34', 'a1_340', 'a1_341', 'a1_342', 'a1_343', 'a1_344', 'a1_345', 'a1_346', 'a1_347', 'a1_348', 'a1_349', 'a1_35', 'a1_350', 'a1_351', 'a1_352', 'a1_353', 'a1_354', 'a1_355', 'a1_356', 'a1_357', 'a1_358', 'a1_359', 'a1_36', 'a1_360', 'a1_361', 'a1_362', 'a1_363', 'a1_364', 'a1_365', 'a1_366', 'a1_367', 'a1_368', 'a1_369', 'a1_37', 'a1_370', 'a1_371', 'a1_372', 'a1_373', 'a1_374', 'a1_375', 'a1_376', 'a1_377', 'a1_378', 'a1_379', 'a1_38', 'a1_380', 'a1_381', 'a1_382', 'a1_383', 'a1_384', 'a1_385', 'a1_386', 'a1_387', 'a1_388', 'a1_389', 'a1_39', 'a1_390', 'a1_391', 'a1_392', 'a1_393', 'a1_394', 'a1_395', 'a1_396', 'a1_397', 'a1_398', 'a1_399', 'a1_4', 'a1_40', 'a1_400', 'a1_401', 'a1_402', 'a1_403', 'a1_404', 'a1_405', 'a1_406', 'a1_407', 'a1_408', 'a1_409', 'a1_41', 'a1_410', 'a1_411', 'a1_412', 'a1_413', 'a1_414', 'a1_415', 'a1_416', 'a1_417', 'a1_418', 'a1_419', 'a1_42', 'a1_420', 'a1_421', 'a1_422', 'a1_423', 'a1_424', 'a1_425', 'a1_426', 'a1_427', 'a1_428', 'a1_429', 'a1_43', 'a1_430', 'a1_431', 'a1_432', 'a1_433', 'a1_434', 'a1_435', 'a1_436', 'a1_437', 'a1_438', 'a1_439', 'a1_44', 'a1_440', 'a1_441', 'a1_442', 'a1_443', 'a1_444', 'a1_445', 'a1_446', 'a1_447', 'a1_448', 'a1_449', 'a1_45', 'a1_450', 'a1_451', 'a1_452', 'a1_453', 'a1_454', 'a1_455', 'a1_456', 'a1_457', 'a1_458', 'a1_459', 'a1_46', 'a1_460', 'a1_461', 'a1_462', 'a1_463', 'a1_464', 'a1_465', 'a1_466', 'a1_467', 'a1_468', 'a1_469', 'a1_47', 'a1_470', 'a1_471', 'a1_472', 'a1_473', 'a1_474', 'a1_475', 'a1_476', 'a1_477', 'a1_478', 'a1_479', 'a1_48', 'a1_480', 'a1_481', 'a1_482', 'a1_483', 'a1_484', 'a1_485', 'a1_486', 'a1_487', 'a1_488', 'a1_489', 'a1_49', 'a1_490', 'a1_491', 'a1_492', 'a1_493', 'a1_494', 'a1_495', 'a1_496', 'a1_497', 'a1_498', 'a1_499', 'a1_5', 'a1_50', 'a1_500', 'a1_501', 'a1_502', 'a1_503', 'a1_504', 'a1_505', 'a1_506', 'a1_507', 'a1_508', 'a1_509', 'a1_51', 'a1_510', 'a1_511', 'a1_512', 'a1_513', 'a1_514', 'a1_515', 'a1_516', 'a1_517', 'a1_518', 'a1_519', 'a1_52', 'a1_520', 'a1_521', 'a1_522', 'a1_523', 'a1_524', 'a1_525', 'a1_526', 'a1_527', 'a1_528', 'a1_529', 'a1_53', 'a1_530', 'a1_531', 'a1_532', 'a1_533', 'a1_534', 'a1_535', 'a1_536', 'a1_537', 'a1_538', 'a1_539', 'a1_54', 'a1_540', 'a1_541', 'a1_542', 'a1_543', 'a1_544', 'a1_545', 'a1_546', 'a1_547', 'a1_548', 'a1_549', 'a1_55', 'a1_550', 'a1_551', 'a1_552', 'a1_553', 'a1_554', 'a1_555', 'a1_556', 'a1_557', 'a1_558', 'a1_559', 'a1_56', 'a1_560', 'a1_561', 'a1_562', 'a1_563', 'a1_564', 'a1_565', 'a1_566', 'a1_567', 'a1_568', 'a1_569', 'a1_57', 'a1_570', 'a1_571', 'a1_572', 'a1_573', 'a1_574', 'a1_575', 'a1_576', 'a1_577', 'a1_578', 'a1_579', 'a1_58', 'a1_580', 'a1_581', 'a1_582', 'a1_583', 'a1_584', 'a1_585', 'a1_586', 'a1_587', 'a1_588', 'a1_589', 'a1_59', 'a1_590', 'a1_591', 'a1_592', 'a1_593', 'a1_594', 'a1_595', 'a1_596', 'a1_597', 'a1_598', 'a1_599', 'a1_6', 'a1_60', 'a1_600', 'a1_601', 'a1_602', 'a1_603', 'a1_604', 'a1_605', 'a1_606', 'a1_607', 'a1_608', 'a1_609', 'a1_61', 'a1_610', 'a1_611', 'a1_612', 'a1_613', 'a1_614', 'a1_615', 'a1_616', 'a1_617', 'a1_618', 'a1_619', 'a1_62', 'a1_620', 'a1_621', 'a1_622', 'a1_623', 'a1_624', 'a1_625', 'a1_626', 'a1_627', 'a1_628', 'a1_629', 'a1_63', 'a1_630', 'a1_631', 'a1_632', 'a1_633', 'a1_634', 'a1_635', 'a1_636', 'a1_637', 'a1_638', 'a1_639', 'a1_64', 'a1_640', 'a1_641', 'a1_642', 'a1_643', 'a1_644', 'a1_645', 'a1_646', 'a1_647', 'a1_648', 'a1_649', 'a1_65', 'a1_650', 'a1_651', 'a1_652', 'a1_653', 'a1_654', 'a1_655', 'a1_656', 'a1_657', 'a1_658', 'a1_659', 'a1_66', 'a1_660', 'a1_661', 'a1_662', 'a1_663', 'a1_664', 'a1_665', 'a1_666', 'a1_667', 'a1_668', 'a1_669', 'a1_67', 'a1_670', 'a1_671', 'a1_672', 'a1_673', 'a1_674', 'a1_675', 'a1_676', 'a1_677', 'a1_678', 'a1_679', 'a1_68', 'a1_680', 'a1_681', 'a1_682', 'a1_683', 'a1_684', 'a1_685', 'a1_686', 'a1_687', 'a1_688', 'a1_689', 'a1_69', 'a1_690', 'a1_691', 'a1_692', 'a1_693', 'a1_694', 'a1_695', 'a1_696', 'a1_697', 'a1_698', 'a1_699', 'a1_7', 'a1_70', 'a1_700', 'a1_701', 'a1_702', 'a1_703', 'a1_704', 'a1_705', 'a1_706', 'a1_707', 'a1_708', 'a1_709', 'a1_71', 'a1_710', 'a1_711', 'a1_712', 'a1_713', 'a1_714', 'a1_715', 'a1_716', 'a1_717', 'a1_718', 'a1_719', 'a1_72', 'a1_720', 'a1_721', 'a1_722', 'a1_723', 'a1_724', 'a1_725', 'a1_726', 'a1_727', 'a1_728', 'a1_729', 'a1_73', 'a1_730', 'a1_731', 'a1_732', 'a1_733', 'a1_734', 'a1_735', 'a1_736', 'a1_737', 'a1_738', 'a1_739', 'a1_74', 'a1_740', 'a1_741', 'a1_742', 'a1_743', 'a1_744', 'a1_745', 'a1_746', 'a1_747', 'a1_748', 'a1_749', 'a1_75', 'a1_750', 'a1_751', 'a1_752', 'a1_753', 'a1_754', 'a1_755', 'a1_756', 'a1_757', 'a1_758', 'a1_759', 'a1_76', 'a1_760', 'a1_761', 'a1_762', 'a1_763', 'a1_764', 'a1_765', 'a1_766', 'a1_767', 'a1_768', 'a1_769', 'a1_77', 'a1_770', 'a1_771', 'a1_772', 'a1_773', 'a1_774', 'a1_775', 'a1_776', 'a1_777', 'a1_778', 'a1_779', 'a1_78', 'a1_780', 'a1_781', 'a1_782', 'a1_783', 'a1_784', 'a1_785', 'a1_786', 'a1_787', 'a1_788', 'a1_789', 'a1_79', 'a1_790', 'a1_791', 'a1_792', 'a1_793', 'a1_794', 'a1_795', 'a1_796', 'a1_797', 'a1_798', 'a1_799', 'a1_8', 'a1_80', 'a1_800', 'a1_801', 'a1_802', 'a1_803', 'a1_804', 'a1_805', 'a1_806', 'a1_807', 'a1_808', 'a1_809', 'a1_81', 'a1_810', 'a1_811', 'a1_812', 'a1_813', 'a1_814', 'a1_815', 'a1_816', 'a1_817', 'a1_818', 'a1_819', 'a1_82', 'a1_820', 'a1_821', 'a1_822', 'a1_823', 'a1_824', 'a1_825', 'a1_826', 'a1_827', 'a1_828', 'a1_829', 'a1_83', 'a1_830', 'a1_831', 'a1_832', 'a1_833', 'a1_834', 'a1_835', 'a1_836', 'a1_837', 'a1_838', 'a1_839', 'a1_84', 'a1_840', 'a1_841', 'a1_842', 'a1_843', 'a1_844', 'a1_845', 'a1_846', 'a1_847', 'a1_848', 'a1_849', 'a1_85', 'a1_850', 'a1_851', 'a1_852', 'a1_853', 'a1_854', 'a1_855', 'a1_856', 'a1_857', 'a1_858', 'a1_859', 'a1_86', 'a1_860', 'a1_861', 'a1_862', 'a1_863', 'a1_864', 'a1_865', 'a1_866', 'a1_867', 'a1_868', 'a1_869', 'a1_87', 'a1_870', 'a1_871', 'a1_872', 'a1_873', 'a1_874', 'a1_875', 'a1_876', 'a1_877', 'a1_878', 'a1_879', 'a1_88', 'a1_880', 'a1_881', 'a1_882', 'a1_883', 'a1_884', 'a1_885', 'a1_886', 'a1_887', 'a1_888', 'a1_889', 'a1_89', 'a1_890', 'a1_891', 'a1_892', 'a1_893', 'a1_894', 'a1_895', 'a1_896', 'a1_897', 'a1_898', 'a1_899', 'a1_9', 'a1_90', 'a1_900', 'a1_901', 'a1_902', 'a1_903', 'a1_904', 'a1_905', 'a1_906', 'a1_907', 'a1_908', 'a1_909', 'a1_91', 'a1_910', 'a1_911', 'a1_912', 'a1_913', 'a1_914', 'a1_915', 'a1_916', 'a1_917', 'a1_918', 'a1_919', 'a1_92', 'a1_920', 'a1_921', 'a1_922', 'a1_923', 'a1_924', 'a1_925', 'a1_926', 'a1_927', 'a1_928', 'a1_929', 'a1_93', 'a1_930', 'a1_931', 'a1_932', 'a1_933', 'a1_934', 'a1_935', 'a1_936', 'a1_937', 'a1_938', 'a1_939', 'a1_94', 'a1_940', 'a1_941', 'a1_942', 'a1_943', 'a1_944', 'a1_945', 'a1_946', 'a1_947', 'a1_948', 'a1_949', 'a1_95', 'a1_950', 'a1_951', 'a1_952', 'a1_953', 'a1_954', 'a1_955', 'a1_956', 'a1_957', 'a1_958', 'a1_959', 'a1_96', 'a1_960', 'a1_961', 'a1_962', 'a1_963', 'a1_964', 'a1_965', 'a1_966', 'a1_967', 'a1_968', 'a1_969', 'a1_97', 'a1_970', 'a1_971', 'a1_972', 'a1_973', 'a1_974', 'a1_975', 'a1_976', 'a1_977', 'a1_978', 'a1_979', 'a1_98', 'a1_980', 'a1_981', 'a1_982', 'a1_983', 'a1_984', 'a1_985', 'a1_986', 'a1_987', 'a1_988', 'a1_989', 'a1_99', 'a1_990', 'a1_991', 'a1_992', 'a1_993', 'a1_994', 'a1_995', 'a1_996', 'a1_997', 'a1_998', 'a1_999']\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "['a1_0', 'a1_1', 'a1_2', 'a1_3', 'a1_4', 'a1_5', 'a1_6', 'a1_7', 'a1_8', 'a1_9', 'a1_10', 'a1_11', 'a1_12', 'a1_13', 'a1_14', 'a1_15', 'a1_16', 'a1_17', 'a1_18', 'a1_19', 'a1_20', 'a1_21', 'a1_22', 'a1_23', 'a1_24', 'a1_25', 'a1_26', 'a1_27', 'a1_28', 'a1_29', 'a1_30', 'a1_31', 'a1_32', 'a1_33', 'a1_34', 'a1_35', 'a1_36', 'a1_37', 'a1_38', 'a1_39', 'a1_40', 'a1_41', 'a1_42', 'a1_43', 'a1_44', 'a1_45', 'a1_46', 'a1_47', 'a1_48', 'a1_49', 'a1_50', 'a1_51', 'a1_52', 'a1_53', 'a1_54', 'a1_55', 'a1_56', 'a1_57', 'a1_58', 'a1_59', 'a1_60', 'a1_61', 'a1_62', 'a1_63', 'a1_64', 'a1_65', 'a1_66', 'a1_67', 'a1_68', 'a1_69', 'a1_70', 'a1_71', 'a1_72', 'a1_73', 'a1_74', 'a1_75', 'a1_76', 'a1_77', 'a1_78', 'a1_79', 'a1_80', 'a1_81', 'a1_82', 'a1_83', 'a1_84', 'a1_85', 'a1_86', 'a1_87', 'a1_88', 'a1_89', 'a1_90', 'a1_91', 'a1_92', 'a1_93', 'a1_94', 'a1_95', 'a1_96', 'a1_97', 'a1_98', 'a1_99', 'a1_100', 'a1_101', 'a1_102', 'a1_103', 'a1_104', 'a1_105', 'a1_106', 'a1_107', 'a1_108', 'a1_109', 'a1_110', 'a1_111', 'a1_112', 'a1_113', 'a1_114', 'a1_115', 'a1_116', 'a1_117', 'a1_118', 'a1_119', 'a1_120', 'a1_121', 'a1_122', 'a1_123', 'a1_124', 'a1_125', 'a1_126', 'a1_127', 'a1_128', 'a1_129', 'a1_130', 'a1_131', 'a1_132', 'a1_133', 'a1_134', 'a1_135', 'a1_136', 'a1_137', 'a1_138', 'a1_139', 'a1_140', 'a1_141', 'a1_142', 'a1_143', 'a1_144', 'a1_145', 'a1_146', 'a1_147', 'a1_148', 'a1_149', 'a1_150', 'a1_151', 'a1_152', 'a1_153', 'a1_154', 'a1_155', 'a1_156', 'a1_157', 'a1_158', 'a1_159', 'a1_160', 'a1_161', 'a1_162', 'a1_163', 'a1_164', 'a1_165', 'a1_166', 'a1_167', 'a1_168', 'a1_169', 'a1_170', 'a1_171', 'a1_172', 'a1_173', 'a1_174', 'a1_175', 'a1_176', 'a1_177', 'a1_178', 'a1_179', 'a1_180', 'a1_181', 'a1_182', 'a1_183', 'a1_184', 'a1_185', 'a1_186', 'a1_187', 'a1_188', 'a1_189', 'a1_190', 'a1_191', 'a1_192', 'a1_193', 'a1_194', 'a1_195', 'a1_196', 'a1_197', 'a1_198', 'a1_199', 'a1_200', 'a1_201', 'a1_202', 'a1_203', 'a1_204', 'a1_205', 'a1_206', 'a1_207', 'a1_208', 'a1_209', 'a1_210', 'a1_211', 'a1_212', 'a1_213', 'a1_214', 'a1_215', 'a1_216', 'a1_217', 'a1_218', 'a1_219', 'a1_220', 'a1_221', 'a1_222', 'a1_223', 'a1_224', 'a1_225', 'a1_226', 'a1_227', 'a1_228', 'a1_229', 'a1_230', 'a1_231', 'a1_232', 'a1_233', 'a1_234', 'a1_235', 'a1_236', 'a1_237', 'a1_238', 'a1_239', 'a1_240', 'a1_241', 'a1_242', 'a1_243', 'a1_244', 'a1_245', 'a1_246', 'a1_247', 'a1_248', 'a1_249', 'a1_250', 'a1_251', 'a1_252', 'a1_253', 'a1_254', 'a1_255', 'a1_256', 'a1_257', 'a1_258', 'a1_259', 'a1_260', 'a1_261', 'a1_262', 'a1_263', 'a1_264', 'a1_265', 'a1_266', 'a1_267', 'a1_268', 'a1_269', 'a1_270', 'a1_271', 'a1_272', 'a1_273', 'a1_274', 'a1_275', 'a1_276', 'a1_277', 'a1_278', 'a1_279', 'a1_280', 'a1_281', 'a1_282', 'a1_283', 'a1_284', 'a1_285', 'a1_286', 'a1_287', 'a1_288', 'a1_289', 'a1_290', 'a1_291', 'a1_292', 'a1_293', 'a1_294', 'a1_295', 'a1_296', 'a1_297', 'a1_298', 'a1_299', 'a1_300', 'a1_301', 'a1_302', 'a1_303', 'a1_304', 'a1_305', 'a1_306', 'a1_307', 'a1_308', 'a1_309', 'a1_310', 'a1_311', 'a1_312', 'a1_313', 'a1_314', 'a1_315', 'a1_316', 'a1_317', 'a1_318', 'a1_319', 'a1_320', 'a1_321', 'a1_322', 'a1_323', 'a1_324', 'a1_325', 'a1_326', 'a1_327', 'a1_328', 'a1_329', 'a1_330', 'a1_331', 'a1_332', 'a1_333', 'a1_334', 'a1_335', 'a1_336', 'a1_337', 'a1_338', 'a1_339', 'a1_340', 'a1_341', 'a1_342', 'a1_343', 'a1_344', 'a1_345', 'a1_346', 'a1_347', 'a1_348', 'a1_349', 'a1_350', 'a1_351', 'a1_352', 'a1_353', 'a1_354', 'a1_355', 'a1_356', 'a1_357', 'a1_358', 'a1_359', 'a1_360', 'a1_361', 'a1_362', 'a1_363', 'a1_364', 'a1_365', 'a1_366', 'a1_367', 'a1_368', 'a1_369', 'a1_370', 'a1_371', 'a1_372', 'a1_373', 'a1_374', 'a1_375', 'a1_376', 'a1_377', 'a1_378', 'a1_379', 'a1_380', 'a1_381', 'a1_382', 'a1_383', 'a1_384', 'a1_385', 'a1_386', 'a1_387', 'a1_388', 'a1_389', 'a1_390', 'a1_391', 'a1_392', 'a1_393', 'a1_394', 'a1_395', 'a1_396', 'a1_397', 'a1_398', 'a1_399', 'a1_400', 'a1_401', 'a1_402', 'a1_403', 'a1_404', 'a1_405', 'a1_406', 'a1_407', 'a1_408', 'a1_409', 'a1_410', 'a1_411', 'a1_412', 'a1_413', 'a1_414', 'a1_415', 'a1_416', 'a1_417', 'a1_418', 'a1_419', 'a1_420', 'a1_421', 'a1_422', 'a1_423', 'a1_424', 'a1_425', 'a1_426', 'a1_427', 'a1_428', 'a1_429', 'a1_430', 'a1_431', 'a1_432', 'a1_433', 'a1_434', 'a1_435', 'a1_436', 'a1_437', 'a1_438', 'a1_439', 'a1_440', 'a1_441', 'a1_442', 'a1_443', 'a1_444', 'a1_445', 'a1_446', 'a1_447', 'a1_448', 'a1_449', 'a1_450', 'a1_451', 'a1_452', 'a1_453', 'a1_454', 'a1_455', 'a1_456', 'a1_457', 'a1_458', 'a1_459', 'a1_460', 'a1_461', 'a1_462', 'a1_463', 'a1_464', 'a1_465', 'a1_466', 'a1_467', 'a1_468', 'a1_469', 'a1_470', 'a1_471', 'a1_472', 'a1_473', 'a1_474', 'a1_475', 'a1_476', 'a1_477', 'a1_478', 'a1_479', 'a1_480', 'a1_481', 'a1_482', 'a1_483', 'a1_484', 'a1_485', 'a1_486', 'a1_487', 'a1_488', 'a1_489', 'a1_490', 'a1_491', 'a1_492', 'a1_493', 'a1_494', 'a1_495', 'a1_496', 'a1_497', 'a1_498', 'a1_499', 'a1_500', 'a1_501', 'a1_502', 'a1_503', 'a1_504', 'a1_505', 'a1_506', 'a1_507', 'a1_508', 'a1_509', 'a1_510', 'a1_511', 'a1_512', 'a1_513', 'a1_514', 'a1_515', 'a1_516', 'a1_517', 'a1_518', 'a1_519', 'a1_520', 'a1_521', 'a1_522', 'a1_523', 'a1_524', 'a1_525', 'a1_526', 'a1_527', 'a1_528', 'a1_529', 'a1_530', 'a1_531', 'a1_532', 'a1_533', 'a1_534', 'a1_535', 'a1_536', 'a1_537', 'a1_538', 'a1_539', 'a1_540', 'a1_541', 'a1_542', 'a1_543', 'a1_544', 'a1_545', 'a1_546', 'a1_547', 'a1_548', 'a1_549', 'a1_550', 'a1_551', 'a1_552', 'a1_553', 'a1_554', 'a1_555', 'a1_556', 'a1_557', 'a1_558', 'a1_559', 'a1_560', 'a1_561', 'a1_562', 'a1_563', 'a1_564', 'a1_565', 'a1_566', 'a1_567', 'a1_568', 'a1_569', 'a1_570', 'a1_571', 'a1_572', 'a1_573', 'a1_574', 'a1_575', 'a1_576', 'a1_577', 'a1_578', 'a1_579', 'a1_580', 'a1_581', 'a1_582', 'a1_583', 'a1_584', 'a1_585', 'a1_586', 'a1_587', 'a1_588', 'a1_589', 'a1_590', 'a1_591', 'a1_592', 'a1_593', 'a1_594', 'a1_595', 'a1_596', 'a1_597', 'a1_598', 'a1_599', 'a1_600', 'a1_601', 'a1_602', 'a1_603', 'a1_604', 'a1_605', 'a1_606', 'a1_607', 'a1_608', 'a1_609', 'a1_610', 'a1_611', 'a1_612', 'a1_613', 'a1_614', 'a1_615', 'a1_616', 'a1_617', 'a1_618', 'a1_619', 'a1_620', 'a1_621', 'a1_622', 'a1_623', 'a1_624', 'a1_625', 'a1_626', 'a1_627', 'a1_628', 'a1_629', 'a1_630', 'a1_631', 'a1_632', 'a1_633', 'a1_634', 'a1_635', 'a1_636', 'a1_637', 'a1_638', 'a1_639', 'a1_640', 'a1_641', 'a1_642', 'a1_643', 'a1_644', 'a1_645', 'a1_646', 'a1_647', 'a1_648', 'a1_649', 'a1_650', 'a1_651', 'a1_652', 'a1_653', 'a1_654', 'a1_655', 'a1_656', 'a1_657', 'a1_658', 'a1_659', 'a1_660', 'a1_661', 'a1_662', 'a1_663', 'a1_664', 'a1_665', 'a1_666', 'a1_667', 'a1_668', 'a1_669', 'a1_670', 'a1_671', 'a1_672', 'a1_673', 'a1_674', 'a1_675', 'a1_676', 'a1_677', 'a1_678', 'a1_679', 'a1_680', 'a1_681', 'a1_682', 'a1_683', 'a1_684', 'a1_685', 'a1_686', 'a1_687', 'a1_688', 'a1_689', 'a1_690', 'a1_691', 'a1_692', 'a1_693', 'a1_694', 'a1_695', 'a1_696', 'a1_697', 'a1_698', 'a1_699', 'a1_700', 'a1_701', 'a1_702', 'a1_703', 'a1_704', 'a1_705', 'a1_706', 'a1_707', 'a1_708', 'a1_709', 'a1_710', 'a1_711', 'a1_712', 'a1_713', 'a1_714', 'a1_715', 'a1_716', 'a1_717', 'a1_718', 'a1_719', 'a1_720', 'a1_721', 'a1_722', 'a1_723', 'a1_724', 'a1_725', 'a1_726', 'a1_727', 'a1_728', 'a1_729', 'a1_730', 'a1_731', 'a1_732', 'a1_733', 'a1_734', 'a1_735', 'a1_736', 'a1_737', 'a1_738', 'a1_739', 'a1_740', 'a1_741', 'a1_742', 'a1_743', 'a1_744', 'a1_745', 'a1_746', 'a1_747', 'a1_748', 'a1_749', 'a1_750', 'a1_751', 'a1_752', 'a1_753', 'a1_754', 'a1_755', 'a1_756', 'a1_757', 'a1_758', 'a1_759', 'a1_760', 'a1_761', 'a1_762', 'a1_763', 'a1_764', 'a1_765', 'a1_766', 'a1_767', 'a1_768', 'a1_769', 'a1_770', 'a1_771', 'a1_772', 'a1_773', 'a1_774', 'a1_775', 'a1_776', 'a1_777', 'a1_778', 'a1_779', 'a1_780', 'a1_781', 'a1_782', 'a1_783', 'a1_784', 'a1_785', 'a1_786', 'a1_787', 'a1_788', 'a1_789', 'a1_790', 'a1_791', 'a1_792', 'a1_793', 'a1_794', 'a1_795', 'a1_796', 'a1_797', 'a1_798', 'a1_799', 'a1_800', 'a1_801', 'a1_802', 'a1_803', 'a1_804', 'a1_805', 'a1_806', 'a1_807', 'a1_808', 'a1_809', 'a1_810', 'a1_811', 'a1_812', 'a1_813', 'a1_814', 'a1_815', 'a1_816', 'a1_817', 'a1_818', 'a1_819', 'a1_820', 'a1_821', 'a1_822', 'a1_823', 'a1_824', 'a1_825', 'a1_826', 'a1_827', 'a1_828', 'a1_829', 'a1_830', 'a1_831', 'a1_832', 'a1_833', 'a1_834', 'a1_835', 'a1_836', 'a1_837', 'a1_838', 'a1_839', 'a1_840', 'a1_841', 'a1_842', 'a1_843', 'a1_844', 'a1_845', 'a1_846', 'a1_847', 'a1_848', 'a1_849', 'a1_850', 'a1_851', 'a1_852', 'a1_853', 'a1_854', 'a1_855', 'a1_856', 'a1_857', 'a1_858', 'a1_859', 'a1_860', 'a1_861', 'a1_862', 'a1_863', 'a1_864', 'a1_865', 'a1_866', 'a1_867', 'a1_868', 'a1_869', 'a1_870', 'a1_871', 'a1_872', 'a1_873', 'a1_874', 'a1_875', 'a1_876', 'a1_877', 'a1_878', 'a1_879', 'a1_880', 'a1_881', 'a1_882', 'a1_883', 'a1_884', 'a1_885', 'a1_886', 'a1_887', 'a1_888', 'a1_889', 'a1_890', 'a1_891', 'a1_892', 'a1_893', 'a1_894', 'a1_895', 'a1_896', 'a1_897', 'a1_898', 'a1_899', 'a1_900', 'a1_901', 'a1_902', 'a1_903', 'a1_904', 'a1_905', 'a1_906', 'a1_907', 'a1_908', 'a1_909', 'a1_910', 'a1_911', 'a1_912', 'a1_913', 'a1_914', 'a1_915', 'a1_916', 'a1_917', 'a1_918', 'a1_919', 'a1_920', 'a1_921', 'a1_922', 'a1_923', 'a1_924', 'a1_925', 'a1_926', 'a1_927', 'a1_928', 'a1_929', 'a1_930', 'a1_931', 'a1_932', 'a1_933', 'a1_934', 'a1_935', 'a1_936', 'a1_937', 'a1_938', 'a1_939', 'a1_940', 'a1_941', 'a1_942', 'a1_943', 'a1_944', 'a1_945', 'a1_946', 'a1_947', 'a1_948', 'a1_949', 'a1_950', 'a1_951', 'a1_952', 'a1_953', 'a1_954', 'a1_955', 'a1_956', 'a1_957', 'a1_958', 'a1_959', 'a1_960', 'a1_961', 'a1_962', 'a1_963', 'a1_964', 'a1_965', 'a1_966', 'a1_967', 'a1_968', 'a1_969', 'a1_970', 'a1_971', 'a1_972', 'a1_973', 'a1_974', 'a1_975', 'a1_976', 'a1_977', 'a1_978', 'a1_979', 'a1_980', 'a1_981', 'a1_982', 'a1_983', 'a1_984', 'a1_985', 'a1_986', 'a1_987', 'a1_988', 'a1_989', 'a1_990', 'a1_991', 'a1_992', 'a1_993', 'a1_994', 'a1_995', 'a1_996', 'a1_997', 'a1_998', 'a1_999']\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m pic_list \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(current_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/train/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m i)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m pic_list:\n\u001b[1;32m---> 53\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data/train/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img)\n\u001b[0;32m     55\u001b[0m     img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(img)\n",
      "File \u001b[1;32md:\\apps\\ANACONDA\\Lib\\site-packages\\PIL\\Image.py:3218\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3215\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3218\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3219\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# data preprocessing ./data/train\n",
    "current_dir = os.getcwd()\n",
    "# train data\n",
    "train_list = os.listdir(current_dir + '/data/train')\n",
    "# Total classes\n",
    "n = len(train_list)\n",
    "# pic size 64*64*3\n",
    "pic_list = os.listdir(current_dir + '/data/train/' + train_list[0])\n",
    "pic = Image.open(current_dir + '/data/train/' + train_list[0] + '/' + pic_list[0])\n",
    "pic = np.array(pic)\n",
    "pic_size = pic.shape\n",
    "print(pic_size)\n",
    "\n",
    "\n",
    "# label\n",
    "label = train_list\n",
    "print(label)\n",
    "\n",
    "# one-hot encoding\n",
    "def one_hot(label):\n",
    "    n = len(label)\n",
    "    one_hot_label = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        # a1_xxx -> xxx\n",
    "        hot = int(label[i].split('_')[1])\n",
    "        one_hot_label[i][hot] = 1\n",
    "    return one_hot_label\n",
    "#test one_hot\n",
    "one_hot_label = one_hot(label)\n",
    "print(one_hot_label)\n",
    "# sort by one_hot_label.argmax() zip with label\n",
    "label = [x for _, x in sorted(zip(one_hot_label.argmax(axis=1), label))]\n",
    "one_hot_label = one_hot(label)\n",
    "print(label)\n",
    "print(one_hot_label)\n",
    "\n",
    "#generate X_train and Y_train\n",
    "# for i in range(batch_size):\n",
    "#     test_img = Image.open(current_dir + '/data/train/' + train_list[test_train_index] + '/' + pic_list[i])\n",
    "#     test_img = np.array(test_img)\n",
    "#     test_img = torch.tensor(test_img)\n",
    "#     test_img = test_img.permute(2, 0, 1)\n",
    "#     test_img = test_img.unsqueeze(0).float()\n",
    "#     test_img = test_img.to(device)\n",
    "#     test_list.append(test_img)\n",
    "\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for i in train_list:\n",
    "    pic_list = os.listdir(current_dir + '/data/train/' + i)\n",
    "    for j in pic_list:\n",
    "        img = Image.open(current_dir + '/data/train/' + i + '/' + j)\n",
    "        img = np.array(img)\n",
    "        img = torch.tensor(img)\n",
    "        img = img.permute(2, 0, 1)\n",
    "        img = img.unsqueeze(0).float()\n",
    "        X_train.append(img)\n",
    "        Y_train.append(one_hot_label[train_list.index(i)])\n",
    "X_train = torch.cat(X_train, dim=0)\n",
    "Y_train = torch.tensor(Y_train)\n",
    "\n",
    "# generate X_val and Y_val\n",
    "X_val = []\n",
    "Y_val = []\n",
    "val_list = os.listdir(current_dir + '/data/val')\n",
    "for i in val_list:\n",
    "    pic_list = os.listdir(current_dir + '/data/val/' + i)\n",
    "    for j in pic_list:\n",
    "        img = Image.open(current_dir + '/data/val/' + i + '/' + j)\n",
    "        img = np.array(img)\n",
    "        img = torch.tensor(img)\n",
    "        img = img.permute(2, 0, 1)\n",
    "        img = img.unsqueeze(0).float()\n",
    "        X_val.append(img)\n",
    "        Y_val.append(one_hot_label[train_list.index(i)])\n",
    "X_val = torch.cat(X_val, dim=0)\n",
    "Y_val = torch.tensor(Y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(Y_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_val\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)\n",
    "# print(X_train[0],Y_train[0])\n",
    "# save preprocessed data\n",
    "# torch.save(X_train, 'X_train.pt')\n",
    "# torch.save(Y_train, 'Y_train.pt')\n",
    "# torch.save(X_val, 'X_val.pt')\n",
    "# torch.save(Y_val, 'Y_val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# load preprocessed data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m Y_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_train.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m X_val \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_val.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# load preprocessed data\n",
    "X_train = torch.load('X_train.pt')\n",
    "Y_train = torch.load('Y_train.pt')\n",
    "X_val = torch.load('X_val.pt')\n",
    "Y_val = torch.load('Y_val.pt')\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  7.,   7.,   7.,  ...,  96.,  98.,  93.],\n",
      "         [  7.,   7.,   7.,  ...,  97.,  98.,  93.],\n",
      "         [  7.,   7.,   7.,  ...,  97.,  98.,  93.],\n",
      "         ...,\n",
      "         [ 10.,  13.,  12.,  ...,  18.,  20.,  27.],\n",
      "         [ 10.,  11.,   9.,  ...,  36.,  47.,  43.],\n",
      "         [ 12.,  12.,   9.,  ...,  40.,  31.,  34.]],\n",
      "\n",
      "        [[  8.,   8.,   8.,  ..., 100., 105., 101.],\n",
      "         [  8.,   8.,   8.,  ..., 101., 105., 101.],\n",
      "         [  8.,   8.,   8.,  ..., 101., 105., 101.],\n",
      "         ...,\n",
      "         [ 12.,  15.,  14.,  ...,  19.,  21.,  29.],\n",
      "         [ 12.,  13.,  11.,  ...,  37.,  48.,  45.],\n",
      "         [ 14.,  14.,  11.,  ...,  41.,  32.,  36.]],\n",
      "\n",
      "        [[  3.,   3.,   3.,  ...,  85.,  87.,  80.],\n",
      "         [  3.,   3.,   3.,  ...,  86.,  87.,  80.],\n",
      "         [  3.,   3.,   3.,  ...,  86.,  87.,  80.],\n",
      "         ...,\n",
      "         [  0.,   2.,   1.,  ...,  24.,  23.,  28.],\n",
      "         [  0.,   0.,   0.,  ...,  42.,  52.,  44.],\n",
      "         [  0.,   1.,   0.,  ...,  46.,  36.,  35.]]], device='cuda:0') tensor(436, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# zip X_train and Y_train and shuffle\n",
    "train_data = list(zip(X_train, Y_train))\n",
    "random.shuffle(train_data)\n",
    "X_train, Y_train = zip(*train_data)\n",
    "X_train = torch.stack(X_train)\n",
    "Y_train = torch.stack(Y_train)\n",
    "print(X_train[0], Y_train[0].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "    (4): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\SWORWOOD/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
    "# open all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "# change the last layer\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(512, 1000),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(1000, 1000),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 96, 11, 1, 2)\n",
    "        # relu and maxpool\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(3, 2)\n",
    "        # 5*5 kernel and 2 padding 256 output\n",
    "        self.conv2 = nn.Conv2d(96, 256, 5, 1, 2)\n",
    "        # relu and maxpool\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(3, 2)\n",
    "        # 3*3 kernel and 1 padding 384 output\n",
    "        self.conv3 = nn.Conv2d(256, 384, 3, 1, 1)\n",
    "        # relu\n",
    "        self.relu3 = nn.ReLU()\n",
    "        # 3*3 kernel and 1 padding 384 output\n",
    "        self.conv4 = nn.Conv2d(384, 384, 3, 1, 1)\n",
    "        # relu\n",
    "        self.relu4 = nn.ReLU()\n",
    "        # 3*3 kernel and 1 padding 256 output\n",
    "        self.conv5 = nn.Conv2d(384, 256, 3, 1, 1)\n",
    "        # relu and maxpool\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(3, 2)\n",
    "        # flatten\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 1000)\n",
    "        # relu and dropout 0.5\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        # relu and dropout 0.5\n",
    "        self.relu7 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(1000, 1000)\n",
    "        # softmax\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.maxpool3(x)\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 256 * 6 * 6)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu7(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "0\n",
      "NVIDIA GeForce RTX 4080 NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "# show device list\n",
    "print(torch.cuda.device_count())\n",
    "# show current device\n",
    "print(torch.cuda.current_device())\n",
    "# show device name\n",
    "print(torch.cuda.get_device_name(0), torch.cuda.get_device_name(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "source": [
    "# test if cuda is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([93134, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Parameter containing:\n",
      "tensor([[ 3.5390e-01, -1.9170e-01, -1.7490e+00,  ...,  2.8186e+00,\n",
      "          6.8441e-02, -3.9604e-01],\n",
      "        [ 1.3347e+00, -7.9010e-02,  1.3574e+00,  ..., -9.8574e-01,\n",
      "         -4.1473e-01,  1.8702e-01],\n",
      "        [-1.0058e-01, -1.9555e+00, -3.9382e-01,  ..., -7.7934e-01,\n",
      "         -7.5023e-01,  2.4525e-03],\n",
      "        ...,\n",
      "        [ 4.8253e-01, -8.0432e-02,  1.4863e+00,  ..., -6.3359e-01,\n",
      "         -1.7374e-02, -9.8030e-01],\n",
      "        [-8.4839e-01,  1.8256e+00, -1.1058e-01,  ..., -2.4752e+00,\n",
      "          4.2464e-01,  2.3918e+00],\n",
      "        [-2.0638e+00,  5.5673e-02,  1.2451e+00,  ..., -8.7125e-01,\n",
      "         -1.0455e+00, -1.0634e+00]], device='cuda:0', requires_grad=True)\n",
      "torch.Size([1000, 3, 64, 64])\n",
      "torch.Size([1000, 1000]) torch.Size([1000, 1000])\n",
      "tensor(inf, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#check if the model is on cuda\n",
    "print(model.fc[0].weight.is_cuda)\n",
    "# randomize all the parameters in the model and also the cnn layers\n",
    "def randomize_parameters(model):\n",
    "    for param in model.parameters():\n",
    "        param.data = torch.randn_like(param)\n",
    "randomize_parameters(model)\n",
    "print(model.fc[0].weight)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# test cross entropy loss\n",
    "input = X_train[:1000].to(device)\n",
    "print(input.shape)\n",
    "target = Y_train[:1000].to(device)\n",
    "output = model(input)\n",
    "print(output.shape, target.shape)\n",
    "loss = criterion(output, target.argmax(dim=1))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv1): Conv2d(3, 96, kernel_size=(11, 11), stride=(1, 1), padding=(2, 2))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (conv4): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4): ReLU()\n",
      "  (conv5): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5): ReLU()\n",
      "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=1000, bias=True)\n",
      "  (relu6): ReLU()\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "  (relu7): ReLU()\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc3): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "def initialize_parameters(model):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            # Initialize weights, Normal\n",
    "            init.normal_(module.weight, mean=0, std=0.01)\n",
    "            # Check if bias exists and initialize it\n",
    "            if module.bias is not None:\n",
    "                init.constant_(module.bias, 0)\n",
    "\n",
    "# 创建AlexNet模型\n",
    "model = AlexNet()\n",
    "\n",
    "# 初始化模型参数\n",
    "initialize_parameters(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a1_0', 'a1_1', 'a1_10', 'a1_100', 'a1_101', 'a1_102', 'a1_103', 'a1_104', 'a1_105', 'a1_106', 'a1_107', 'a1_108', 'a1_109', 'a1_11', 'a1_110', 'a1_111', 'a1_112', 'a1_113', 'a1_114', 'a1_115', 'a1_116', 'a1_117', 'a1_118', 'a1_119', 'a1_12', 'a1_120', 'a1_121', 'a1_122', 'a1_123', 'a1_124', 'a1_125', 'a1_126', 'a1_127', 'a1_128', 'a1_129', 'a1_13', 'a1_130', 'a1_131', 'a1_132', 'a1_133', 'a1_134', 'a1_135', 'a1_136', 'a1_137', 'a1_138', 'a1_139', 'a1_14', 'a1_140', 'a1_141', 'a1_142', 'a1_143', 'a1_144', 'a1_145', 'a1_146', 'a1_147', 'a1_148', 'a1_149', 'a1_15', 'a1_150', 'a1_151', 'a1_152', 'a1_153', 'a1_154', 'a1_155', 'a1_156', 'a1_157', 'a1_158', 'a1_159', 'a1_16', 'a1_160', 'a1_161', 'a1_162', 'a1_163', 'a1_164', 'a1_165', 'a1_166', 'a1_167', 'a1_168', 'a1_169', 'a1_17', 'a1_170', 'a1_171', 'a1_172', 'a1_173', 'a1_174', 'a1_175', 'a1_176', 'a1_177', 'a1_178', 'a1_179', 'a1_18', 'a1_180', 'a1_181', 'a1_182', 'a1_183', 'a1_184', 'a1_185', 'a1_186', 'a1_187', 'a1_188', 'a1_189', 'a1_19', 'a1_190', 'a1_191', 'a1_192', 'a1_193', 'a1_194', 'a1_195', 'a1_196', 'a1_197', 'a1_198', 'a1_199', 'a1_2', 'a1_20', 'a1_200', 'a1_201', 'a1_202', 'a1_203', 'a1_204', 'a1_205', 'a1_206', 'a1_207', 'a1_208', 'a1_209', 'a1_21', 'a1_210', 'a1_211', 'a1_212', 'a1_213', 'a1_214', 'a1_215', 'a1_216', 'a1_217', 'a1_218', 'a1_219', 'a1_22', 'a1_220', 'a1_221', 'a1_222', 'a1_223', 'a1_224', 'a1_225', 'a1_226', 'a1_227', 'a1_228', 'a1_229', 'a1_23', 'a1_230', 'a1_231', 'a1_232', 'a1_233', 'a1_234', 'a1_235', 'a1_236', 'a1_237', 'a1_238', 'a1_239', 'a1_24', 'a1_240', 'a1_241', 'a1_242', 'a1_243', 'a1_244', 'a1_245', 'a1_246', 'a1_247', 'a1_248', 'a1_249', 'a1_25', 'a1_250', 'a1_251', 'a1_252', 'a1_253', 'a1_254', 'a1_255', 'a1_256', 'a1_257', 'a1_258', 'a1_259', 'a1_26', 'a1_260', 'a1_261', 'a1_262', 'a1_263', 'a1_264', 'a1_265', 'a1_266', 'a1_267', 'a1_268', 'a1_269', 'a1_27', 'a1_270', 'a1_271', 'a1_272', 'a1_273', 'a1_274', 'a1_275', 'a1_276', 'a1_277', 'a1_278', 'a1_279', 'a1_28', 'a1_280', 'a1_281', 'a1_282', 'a1_283', 'a1_284', 'a1_285', 'a1_286', 'a1_287', 'a1_288', 'a1_289', 'a1_29', 'a1_290', 'a1_291', 'a1_292', 'a1_293', 'a1_294', 'a1_295', 'a1_296', 'a1_297', 'a1_298', 'a1_299', 'a1_3', 'a1_30', 'a1_300', 'a1_301', 'a1_302', 'a1_303', 'a1_304', 'a1_305', 'a1_306', 'a1_307', 'a1_308', 'a1_309', 'a1_31', 'a1_310', 'a1_311', 'a1_312', 'a1_313', 'a1_314', 'a1_315', 'a1_316', 'a1_317', 'a1_318', 'a1_319', 'a1_32', 'a1_320', 'a1_321', 'a1_322', 'a1_323', 'a1_324', 'a1_325', 'a1_326', 'a1_327', 'a1_328', 'a1_329', 'a1_33', 'a1_330', 'a1_331', 'a1_332', 'a1_333', 'a1_334', 'a1_335', 'a1_336', 'a1_337', 'a1_338', 'a1_339', 'a1_34', 'a1_340', 'a1_341', 'a1_342', 'a1_343', 'a1_344', 'a1_345', 'a1_346', 'a1_347', 'a1_348', 'a1_349', 'a1_35', 'a1_350', 'a1_351', 'a1_352', 'a1_353', 'a1_354', 'a1_355', 'a1_356', 'a1_357', 'a1_358', 'a1_359', 'a1_36', 'a1_360', 'a1_361', 'a1_362', 'a1_363', 'a1_364', 'a1_365', 'a1_366', 'a1_367', 'a1_368', 'a1_369', 'a1_37', 'a1_370', 'a1_371', 'a1_372', 'a1_373', 'a1_374', 'a1_375', 'a1_376', 'a1_377', 'a1_378', 'a1_379', 'a1_38', 'a1_380', 'a1_381', 'a1_382', 'a1_383', 'a1_384', 'a1_385', 'a1_386', 'a1_387', 'a1_388', 'a1_389', 'a1_39', 'a1_390', 'a1_391', 'a1_392', 'a1_393', 'a1_394', 'a1_395', 'a1_396', 'a1_397', 'a1_398', 'a1_399', 'a1_4', 'a1_40', 'a1_400', 'a1_401', 'a1_402', 'a1_403', 'a1_404', 'a1_405', 'a1_406', 'a1_407', 'a1_408', 'a1_409', 'a1_41', 'a1_410', 'a1_411', 'a1_412', 'a1_413', 'a1_414', 'a1_415', 'a1_416', 'a1_417', 'a1_418', 'a1_419', 'a1_42', 'a1_420', 'a1_421', 'a1_422', 'a1_423', 'a1_424', 'a1_425', 'a1_426', 'a1_427', 'a1_428', 'a1_429', 'a1_43', 'a1_430', 'a1_431', 'a1_432', 'a1_433', 'a1_434', 'a1_435', 'a1_436', 'a1_437', 'a1_438', 'a1_439', 'a1_44', 'a1_440', 'a1_441', 'a1_442', 'a1_443', 'a1_444', 'a1_445', 'a1_446', 'a1_447', 'a1_448', 'a1_449', 'a1_45', 'a1_450', 'a1_451', 'a1_452', 'a1_453', 'a1_454', 'a1_455', 'a1_456', 'a1_457', 'a1_458', 'a1_459', 'a1_46', 'a1_460', 'a1_461', 'a1_462', 'a1_463', 'a1_464', 'a1_465', 'a1_466', 'a1_467', 'a1_468', 'a1_469', 'a1_47', 'a1_470', 'a1_471', 'a1_472', 'a1_473', 'a1_474', 'a1_475', 'a1_476', 'a1_477', 'a1_478', 'a1_479', 'a1_48', 'a1_480', 'a1_481', 'a1_482', 'a1_483', 'a1_484', 'a1_485', 'a1_486', 'a1_487', 'a1_488', 'a1_489', 'a1_49', 'a1_490', 'a1_491', 'a1_492', 'a1_493', 'a1_494', 'a1_495', 'a1_496', 'a1_497', 'a1_498', 'a1_499', 'a1_5', 'a1_50', 'a1_500', 'a1_501', 'a1_502', 'a1_503', 'a1_504', 'a1_505', 'a1_506', 'a1_507', 'a1_508', 'a1_509', 'a1_51', 'a1_510', 'a1_511', 'a1_512', 'a1_513', 'a1_514', 'a1_515', 'a1_516', 'a1_517', 'a1_518', 'a1_519', 'a1_52', 'a1_520', 'a1_521', 'a1_522', 'a1_523', 'a1_524', 'a1_525', 'a1_526', 'a1_527', 'a1_528', 'a1_529', 'a1_53', 'a1_530', 'a1_531', 'a1_532', 'a1_533', 'a1_534', 'a1_535', 'a1_536', 'a1_537', 'a1_538', 'a1_539', 'a1_54', 'a1_540', 'a1_541', 'a1_542', 'a1_543', 'a1_544', 'a1_545', 'a1_546', 'a1_547', 'a1_548', 'a1_549', 'a1_55', 'a1_550', 'a1_551', 'a1_552', 'a1_553', 'a1_554', 'a1_555', 'a1_556', 'a1_557', 'a1_558', 'a1_559', 'a1_56', 'a1_560', 'a1_561', 'a1_562', 'a1_563', 'a1_564', 'a1_565', 'a1_566', 'a1_567', 'a1_568', 'a1_569', 'a1_57', 'a1_570', 'a1_571', 'a1_572', 'a1_573', 'a1_574', 'a1_575', 'a1_576', 'a1_577', 'a1_578', 'a1_579', 'a1_58', 'a1_580', 'a1_581', 'a1_582', 'a1_583', 'a1_584', 'a1_585', 'a1_586', 'a1_587', 'a1_588', 'a1_589', 'a1_59', 'a1_590', 'a1_591', 'a1_592', 'a1_593', 'a1_594', 'a1_595', 'a1_596', 'a1_597', 'a1_598', 'a1_599', 'a1_6', 'a1_60', 'a1_600', 'a1_601', 'a1_602', 'a1_603', 'a1_604', 'a1_605', 'a1_606', 'a1_607', 'a1_608', 'a1_609', 'a1_61', 'a1_610', 'a1_611', 'a1_612', 'a1_613', 'a1_614', 'a1_615', 'a1_616', 'a1_617', 'a1_618', 'a1_619', 'a1_62', 'a1_620', 'a1_621', 'a1_622', 'a1_623', 'a1_624', 'a1_625', 'a1_626', 'a1_627', 'a1_628', 'a1_629', 'a1_63', 'a1_630', 'a1_631', 'a1_632', 'a1_633', 'a1_634', 'a1_635', 'a1_636', 'a1_637', 'a1_638', 'a1_639', 'a1_64', 'a1_640', 'a1_641', 'a1_642', 'a1_643', 'a1_644', 'a1_645', 'a1_646', 'a1_647', 'a1_648', 'a1_649', 'a1_65', 'a1_650', 'a1_651', 'a1_652', 'a1_653', 'a1_654', 'a1_655', 'a1_656', 'a1_657', 'a1_658', 'a1_659', 'a1_66', 'a1_660', 'a1_661', 'a1_662', 'a1_663', 'a1_664', 'a1_665', 'a1_666', 'a1_667', 'a1_668', 'a1_669', 'a1_67', 'a1_670', 'a1_671', 'a1_672', 'a1_673', 'a1_674', 'a1_675', 'a1_676', 'a1_677', 'a1_678', 'a1_679', 'a1_68', 'a1_680', 'a1_681', 'a1_682', 'a1_683', 'a1_684', 'a1_685', 'a1_686', 'a1_687', 'a1_688', 'a1_689', 'a1_69', 'a1_690', 'a1_691', 'a1_692', 'a1_693', 'a1_694', 'a1_695', 'a1_696', 'a1_697', 'a1_698', 'a1_699', 'a1_7', 'a1_70', 'a1_700', 'a1_701', 'a1_702', 'a1_703', 'a1_704', 'a1_705', 'a1_706', 'a1_707', 'a1_708', 'a1_709', 'a1_71', 'a1_710', 'a1_711', 'a1_712', 'a1_713', 'a1_714', 'a1_715', 'a1_716', 'a1_717', 'a1_718', 'a1_719', 'a1_72', 'a1_720', 'a1_721', 'a1_722', 'a1_723', 'a1_724', 'a1_725', 'a1_726', 'a1_727', 'a1_728', 'a1_729', 'a1_73', 'a1_730', 'a1_731', 'a1_732', 'a1_733', 'a1_734', 'a1_735', 'a1_736', 'a1_737', 'a1_738', 'a1_739', 'a1_74', 'a1_740', 'a1_741', 'a1_742', 'a1_743', 'a1_744', 'a1_745', 'a1_746', 'a1_747', 'a1_748', 'a1_749', 'a1_75', 'a1_750', 'a1_751', 'a1_752', 'a1_753', 'a1_754', 'a1_755', 'a1_756', 'a1_757', 'a1_758', 'a1_759', 'a1_76', 'a1_760', 'a1_761', 'a1_762', 'a1_763', 'a1_764', 'a1_765', 'a1_766', 'a1_767', 'a1_768', 'a1_769', 'a1_77', 'a1_770', 'a1_771', 'a1_772', 'a1_773', 'a1_774', 'a1_775', 'a1_776', 'a1_777', 'a1_778', 'a1_779', 'a1_78', 'a1_780', 'a1_781', 'a1_782', 'a1_783', 'a1_784', 'a1_785', 'a1_786', 'a1_787', 'a1_788', 'a1_789', 'a1_79', 'a1_790', 'a1_791', 'a1_792', 'a1_793', 'a1_794', 'a1_795', 'a1_796', 'a1_797', 'a1_798', 'a1_799', 'a1_8', 'a1_80', 'a1_800', 'a1_801', 'a1_802', 'a1_803', 'a1_804', 'a1_805', 'a1_806', 'a1_807', 'a1_808', 'a1_809', 'a1_81', 'a1_810', 'a1_811', 'a1_812', 'a1_813', 'a1_814', 'a1_815', 'a1_816', 'a1_817', 'a1_818', 'a1_819', 'a1_82', 'a1_820', 'a1_821', 'a1_822', 'a1_823', 'a1_824', 'a1_825', 'a1_826', 'a1_827', 'a1_828', 'a1_829', 'a1_83', 'a1_830', 'a1_831', 'a1_832', 'a1_833', 'a1_834', 'a1_835', 'a1_836', 'a1_837', 'a1_838', 'a1_839', 'a1_84', 'a1_840', 'a1_841', 'a1_842', 'a1_843', 'a1_844', 'a1_845', 'a1_846', 'a1_847', 'a1_848', 'a1_849', 'a1_85', 'a1_850', 'a1_851', 'a1_852', 'a1_853', 'a1_854', 'a1_855', 'a1_856', 'a1_857', 'a1_858', 'a1_859', 'a1_86', 'a1_860', 'a1_861', 'a1_862', 'a1_863', 'a1_864', 'a1_865', 'a1_866', 'a1_867', 'a1_868', 'a1_869', 'a1_87', 'a1_870', 'a1_871', 'a1_872', 'a1_873', 'a1_874', 'a1_875', 'a1_876', 'a1_877', 'a1_878', 'a1_879', 'a1_88', 'a1_880', 'a1_881', 'a1_882', 'a1_883', 'a1_884', 'a1_885', 'a1_886', 'a1_887', 'a1_888', 'a1_889', 'a1_89', 'a1_890', 'a1_891', 'a1_892', 'a1_893', 'a1_894', 'a1_895', 'a1_896', 'a1_897', 'a1_898', 'a1_899', 'a1_9', 'a1_90', 'a1_900', 'a1_901', 'a1_902', 'a1_903', 'a1_904', 'a1_905', 'a1_906', 'a1_907', 'a1_908', 'a1_909', 'a1_91', 'a1_910', 'a1_911', 'a1_912', 'a1_913', 'a1_914', 'a1_915', 'a1_916', 'a1_917', 'a1_918', 'a1_919', 'a1_92', 'a1_920', 'a1_921', 'a1_922', 'a1_923', 'a1_924', 'a1_925', 'a1_926', 'a1_927', 'a1_928', 'a1_929', 'a1_93', 'a1_930', 'a1_931', 'a1_932', 'a1_933', 'a1_934', 'a1_935', 'a1_936', 'a1_937', 'a1_938', 'a1_939', 'a1_94', 'a1_940', 'a1_941', 'a1_942', 'a1_943', 'a1_944', 'a1_945', 'a1_946', 'a1_947', 'a1_948', 'a1_949', 'a1_95', 'a1_950', 'a1_951', 'a1_952', 'a1_953', 'a1_954', 'a1_955', 'a1_956', 'a1_957', 'a1_958', 'a1_959', 'a1_96', 'a1_960', 'a1_961', 'a1_962', 'a1_963', 'a1_964', 'a1_965', 'a1_966', 'a1_967', 'a1_968', 'a1_969', 'a1_97', 'a1_970', 'a1_971', 'a1_972', 'a1_973', 'a1_974', 'a1_975', 'a1_976', 'a1_977', 'a1_978', 'a1_979', 'a1_98', 'a1_980', 'a1_981', 'a1_982', 'a1_983', 'a1_984', 'a1_985', 'a1_986', 'a1_987', 'a1_988', 'a1_989', 'a1_99', 'a1_990', 'a1_991', 'a1_992', 'a1_993', 'a1_994', 'a1_995', 'a1_996', 'a1_997', 'a1_998', 'a1_999']\n",
      "['0142_03.jpg', '0278_02.jpg']\n",
      "nums, channels, height, width:   torch.Size([2, 3, 64, 64])\n",
      "torch.Size([2, 1000])\n",
      "a1_112\n",
      "tensor([123, 387], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# to gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# test img list\n",
    "test_train_index = 16\n",
    "print(train_list)\n",
    "pic_list = os.listdir(current_dir + '/data/val/' + train_list[test_train_index])\n",
    "print(pic_list)\n",
    "# print(model)\n",
    "test_list = []\n",
    "batch_size = len(pic_list)\n",
    "for i in range(batch_size):\n",
    "    test_img = Image.open(current_dir + '/data/val/' + train_list[test_train_index] + '/' + pic_list[i])\n",
    "    test_img = np.array(test_img)\n",
    "    test_img = torch.tensor(test_img)\n",
    "    test_img = test_img.permute(2, 0, 1)\n",
    "    test_img = test_img.unsqueeze(0).float()\n",
    "    test_img = test_img.to(device)\n",
    "    test_list.append(test_img)\n",
    "# form a batch with batch size 10\n",
    "test_list = torch.cat(test_list, 0)\n",
    "print(\"nums, channels, height, width:  \", test_list.shape)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(test_list)\n",
    "    print(output.shape)\n",
    "    # print(output)\n",
    "print(train_list[test_train_index])\n",
    "print(output.argmax(dim=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 3, 64, 64])\n",
      "torch.Size([100, 1000]) torch.Size([100, 1000])\n",
      "tensor([436, 890, 333, 280,  88, 256, 209,   6, 182, 288, 408, 961, 304,  46,\n",
      "        706, 378,  25, 414, 984,  70, 911, 379, 122, 640, 930, 285, 612,  79,\n",
      "        980, 456, 388, 462, 841, 710, 190, 792, 167, 916, 741, 574, 309, 887,\n",
      "        219, 101, 607, 307, 102, 634,  31, 940, 288, 577, 377, 798, 131, 661,\n",
      "        779, 313, 526,  56, 803, 837, 895, 652, 388, 297, 424, 592, 796, 612,\n",
      "        356, 960, 774, 765, 568, 806, 698, 643, 751, 347, 745,  14, 186, 394,\n",
      "        170, 365, 644, 430, 476, 640, 966, 403, 232, 827, 231, 228, 868, 741,\n",
      "        379, 452], device='cuda:0')\n",
      "tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# test cross entropy loss\n",
    "input = X_train[:100].to(device)\n",
    "print(input.shape)\n",
    "target = Y_train[:100].to(device)\n",
    "output = model(input)\n",
    "print(output.shape, target.shape)\n",
    "print(output.argmax(dim=1))\n",
    "loss = criterion(output, target.argmax(dim=1))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # 清空GPU缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=1000, out_features=1000, bias=True)\n",
      "    (4): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model_checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 33.75batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 0.012612993359261101, train acc: 0.009706444477849121\n",
      "epoch: 0, val loss: 0.011713276624679565, val acc: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.42batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train loss: 0.010652421765789576, train acc: 0.04020014173126892\n",
      "epoch: 1, val loss: 0.010413729190826415, val acc: 0.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.44batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, train loss: 0.00938970249252701, train acc: 0.08604805978482616\n",
      "epoch: 2, val loss: 0.009634355545043945, val acc: 0.0845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.36batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, train loss: 0.008446321479849299, train acc: 0.13772628685549854\n",
      "epoch: 3, val loss: 0.00920852518081665, val acc: 0.114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.42batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, train loss: 0.007665353182610538, train acc: 0.18778319410741512\n",
      "epoch: 4, val loss: 0.009025380611419678, val acc: 0.134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.37batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, train loss: 0.006960687229887125, train acc: 0.23643352588743102\n",
      "epoch: 5, val loss: 0.008957994461059571, val acc: 0.1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.46batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, train loss: 0.006319907618467001, train acc: 0.28565293018661286\n",
      "epoch: 6, val loss: 0.009177085399627685, val acc: 0.149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.43batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, train loss: 0.0057499165628872185, train acc: 0.33030901711512445\n",
      "epoch: 7, val loss: 0.009481326580047607, val acc: 0.159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.38batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, train loss: 0.005243078787126573, train acc: 0.3719049971009513\n",
      "epoch: 8, val loss: 0.00965899920463562, val acc: 0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.41batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, train loss: 0.004691612889574338, train acc: 0.42351880086756716\n",
      "epoch: 9, val loss: 0.00993934464454651, val acc: 0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.36batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, train loss: 0.004154983979056673, train acc: 0.47431657611613376\n",
      "epoch: 10, val loss: 0.010626464128494263, val acc: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.49batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, train loss: 0.003673029166846718, train acc: 0.5190263491313591\n",
      "epoch: 11, val loss: 0.011096249341964721, val acc: 0.1945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.51batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, train loss: 0.003270887416825305, train acc: 0.5628449331071359\n",
      "epoch: 12, val loss: 0.011757802724838257, val acc: 0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.53batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, train loss: 0.0028571386708550126, train acc: 0.6085425301178946\n",
      "epoch: 13, val loss: 0.012322967052459716, val acc: 0.1945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.54batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14, train loss: 0.002497830847715229, train acc: 0.6495587003672129\n",
      "epoch: 14, val loss: 0.012985348463058472, val acc: 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.50batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, train loss: 0.002146931358132463, train acc: 0.6910150965275839\n",
      "epoch: 15, val loss: 0.013878660678863525, val acc: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.53batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16, train loss: 0.0018057377779885965, train acc: 0.7348336805033607\n",
      "epoch: 16, val loss: 0.014250178813934327, val acc: 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.56batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17, train loss: 0.0015329525996586205, train acc: 0.769053192174716\n",
      "epoch: 17, val loss: 0.014642698526382445, val acc: 0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.49batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, train loss: 0.0013196697689780515, train acc: 0.7983872699551184\n",
      "epoch: 18, val loss: 0.015146081686019898, val acc: 0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.49batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, train loss: 0.0011125182368586538, train acc: 0.8278394571262911\n",
      "epoch: 19, val loss: 0.01624484133720398, val acc: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.50batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, train loss: 0.0009626763945340901, train acc: 0.849185045203685\n",
      "epoch: 20, val loss: 0.016979494094848634, val acc: 0.2045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.34batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21, train loss: 0.0008564181198651041, train acc: 0.8659028926063521\n",
      "epoch: 21, val loss: 0.01745956611633301, val acc: 0.2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.47batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22, train loss: 0.0007480646474380312, train acc: 0.8813537483625744\n",
      "epoch: 22, val loss: 0.017814205169677733, val acc: 0.2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.48batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23, train loss: 0.000654308359812315, train acc: 0.8962033199476024\n",
      "epoch: 23, val loss: 0.018542975902557372, val acc: 0.1885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.52batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24, train loss: 0.0005893015048342445, train acc: 0.906414413640561\n",
      "epoch: 24, val loss: 0.01871517324447632, val acc: 0.2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.52batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25, train loss: 0.0005281275317415582, train acc: 0.9146498593424528\n",
      "epoch: 25, val loss: 0.01909650707244873, val acc: 0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.51batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26, train loss: 0.00048412057720770307, train acc: 0.9218223205274121\n",
      "epoch: 26, val loss: 0.01931784725189209, val acc: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.50batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27, train loss: 0.0004564464772801905, train acc: 0.9259024631176584\n",
      "epoch: 27, val loss: 0.01980668592453003, val acc: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.52batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28, train loss: 0.0004285990725952731, train acc: 0.9312281229196642\n",
      "epoch: 28, val loss: 0.01988206958770752, val acc: 0.2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.39batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29, train loss: 0.0004089784840236303, train acc: 0.9340412738634656\n",
      "epoch: 29, val loss: 0.020218977451324463, val acc: 0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.50batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30, train loss: 0.0003900185574107617, train acc: 0.9363390383748148\n",
      "epoch: 30, val loss: 0.020835889339447022, val acc: 0.1965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.42batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31, train loss: 0.0003757888399739568, train acc: 0.9390877660145597\n",
      "epoch: 31, val loss: 0.02071465539932251, val acc: 0.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.50batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32, train loss: 0.00038502057964474575, train acc: 0.9374557089784611\n",
      "epoch: 32, val loss: 0.020777636051177977, val acc: 0.2095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.51batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33, train loss: 0.0003615992285067547, train acc: 0.9417398586982197\n",
      "epoch: 33, val loss: 0.0208782639503479, val acc: 0.2165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.50batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34, train loss: 0.0003567626546008137, train acc: 0.9419009169583611\n",
      "epoch: 34, val loss: 0.02115053939819336, val acc: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.47batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35, train loss: 0.0003558006986393601, train acc: 0.942512938346898\n",
      "epoch: 35, val loss: 0.02093362283706665, val acc: 0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.53batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36, train loss: 0.0003260355684757847, train acc: 0.9477204887581334\n",
      "epoch: 36, val loss: 0.021090687751770018, val acc: 0.2105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.51batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37, train loss: 0.0003245019156909868, train acc: 0.9476345910193914\n",
      "epoch: 37, val loss: 0.021474812030792236, val acc: 0.2035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.51batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38, train loss: 0.0003150865841352689, train acc: 0.9494062318809458\n",
      "epoch: 38, val loss: 0.021513407230377198, val acc: 0.2205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.46batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39, train loss: 0.0003109487710752581, train acc: 0.9493095969248609\n",
      "epoch: 39, val loss: 0.021502424716949464, val acc: 0.2165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.48batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40, train loss: 0.00030739875771730076, train acc: 0.9503725814417936\n",
      "epoch: 40, val loss: 0.021688400745391846, val acc: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.57batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41, train loss: 0.0002973266713097053, train acc: 0.951961689608521\n",
      "epoch: 41, val loss: 0.0217284255027771, val acc: 0.2175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.51batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42, train loss: 0.0003124065008406033, train acc: 0.9499108810960551\n",
      "epoch: 42, val loss: 0.02131854486465454, val acc: 0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.51batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43, train loss: 0.00029321338879071914, train acc: 0.9532501556896514\n",
      "epoch: 43, val loss: 0.02178988742828369, val acc: 0.2135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.45batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44, train loss: 0.00027659458657456053, train acc: 0.955365387506174\n",
      "epoch: 44, val loss: 0.02197079038619995, val acc: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.55batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45, train loss: 0.0002806865716120303, train acc: 0.9548929499430927\n",
      "epoch: 45, val loss: 0.0218634090423584, val acc: 0.2195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.53batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46, train loss: 0.00027406655319498564, train acc: 0.9566109047179333\n",
      "epoch: 46, val loss: 0.022372307777404784, val acc: 0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.52batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47, train loss: 0.00027351632253000174, train acc: 0.9562887881976507\n",
      "epoch: 47, val loss: 0.022197389125823974, val acc: 0.2225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.54batch/s]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48, train loss: 0.0002480408675050424, train acc: 0.9594992161831339\n",
      "epoch: 48, val loss: 0.022647048473358154, val acc: 0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch Progress: 187batch [00:05, 35.59batch/s]                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49, train loss: 0.00024340340231370492, train acc: 0.9612493826100028\n",
      "epoch: 49, val loss: 0.023248913288116454, val acc: 0.2115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "# cuda settings\n",
    "torch.cuda.empty_cache()  # 清空GPU缓存\n",
    "torch.backends.cudnn.benchmark = True  # 启用自动寻找最适合当前配置的高效算法\n",
    "torch.backends.cudnn.enabled = True  # 启用cudnn加速\n",
    "# training\n",
    "batch_size = 500\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model.train()\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "epochs = 50\n",
    "# train in cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "X_train = X_train.to(device)\n",
    "Y_train = Y_train.to(device)\n",
    "X_val = X_val.to(device)\n",
    "Y_val = Y_val.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i in tqdm.tqdm(range(0, len(X_train), batch_size), desc='Epoch Progress', unit='batch', total=len(X_train)//batch_size):\n",
    "        inputs = X_train[i:i+batch_size].to(device)\n",
    "        labels = Y_train[i:i+batch_size].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.argmax(dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        running_acc += (outputs.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "    running_loss /= len(X_train)\n",
    "    running_acc /= len(X_train)\n",
    "    train_loss.append(running_loss)\n",
    "    train_acc.append(running_acc)\n",
    "    # if epoch % 10 == 0:\n",
    "    print(f'epoch: {epoch}, train loss: {running_loss}, train acc: {running_acc}')\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_val), batch_size):\n",
    "            inputs = X_val[i:i+batch_size].to(device)\n",
    "            labels = Y_val[i:i+batch_size].to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.argmax(dim=1))\n",
    "            running_loss += loss.item()\n",
    "            running_acc += (outputs.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "        running_loss /= len(X_val)\n",
    "        running_acc /= len(X_val)\n",
    "        val_loss.append(running_loss)\n",
    "        val_acc.append(running_acc)\n",
    "        # if epoch % 10 == 0:\n",
    "        print(f'epoch: {epoch}, val loss: {running_loss}, val acc: {running_acc}')\n",
    "    # save model checkpoint\n",
    "# if epoch % 10 == 0:\n",
    "#     torch.save(model, 'check/model_checkpoint_'+str(epoch)+'_val_acc_'+str(running_acc)+'.pt')\n",
    "    \n",
    "    torch.save(model, 'model_checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'AlexNet' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m Y_val_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY_val.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# model = torch.load('model_checkpoint.pt')\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheck\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmodel_checkpoint_140_val_acc_0.062.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      7\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32md:\\apps\\ANACONDA\\Lib\\site-packages\\torch\\serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1012\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1013\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1014\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1021\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1022\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\apps\\ANACONDA\\Lib\\site-packages\\torch\\serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1420\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1421\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1422\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1424\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1425\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[0;32m   1427\u001b[0m )\n",
      "File \u001b[1;32md:\\apps\\ANACONDA\\Lib\\site-packages\\torch\\serialization.py:1415\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m   1413\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[1;32m-> 1415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfind_class(mod_name, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'AlexNet' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "# load model checkpoint\n",
    "X_val_test = torch.load('X_val.pt')\n",
    "Y_val_test = torch.load('Y_val.pt')\n",
    "# model = torch.load('model_checkpoint.pt')\n",
    "model = torch.load('check\\model_checkpoint_140_val_acc_0.062.pt')\n",
    "model.eval()\n",
    "X_train = X_train.to(device)\n",
    "X_val_test = X_val_test.to(device)\n",
    "test_index = len(X_train)*random.randint(0, 9)//10\n",
    "val_test_index = len(X_val_test)*random.randint(0, 9)//10\n",
    "test = X_train[test_index:test_index+10]\n",
    "val_test = X_val_test[val_test_index:val_test_index+10]\n",
    "print(test.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(test)\n",
    "    print(output.argmax(dim=1), Y_train[test_index:test_index+10].argmax(dim=1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(val_test)\n",
    "    print(output.argmax(dim=1), Y_val_test[val_test_index:val_test_index+10].argmax(dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([695], device='cuda:0') 4\n"
     ]
    }
   ],
   "source": [
    "# take one image from the test set and plot the image and the prediction\n",
    "model = torch.load('model_checkpoint.pt')\n",
    "model.eval()\n",
    "current_dir = os.getcwd()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_path = current_dir + '/data/val/'\n",
    "test_list = os.listdir(test_path)\n",
    "test_index = 4\n",
    "pic_list = os.listdir(test_path + test_list[test_index])\n",
    "pic_index = 0\n",
    "pic = Image.open(test_path + test_list[test_index] + '/' + pic_list[pic_index])\n",
    "Image._show(pic)\n",
    "pic = np.array(pic)\n",
    "pic = torch.tensor(pic)\n",
    "pic = pic.permute(2, 0, 1)\n",
    "pic = pic.unsqueeze(0).float()\n",
    "pic = pic.to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(pic)\n",
    "    print(output.argmax(dim=1), test_list.index(test_list[test_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.091\n"
     ]
    }
   ],
   "source": [
    "# test val acc\n",
    "model = torch.load('model_checkpoint.pt')\n",
    "model.eval()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_val_test = torch.load('X_val.pt')\n",
    "Y_val_test = torch.load('Y_val.pt')\n",
    "X_val_test = X_val_test.to(device)\n",
    "Y_val_test = Y_val_test.to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(X_val_test)\n",
    "    print((output.argmax(dim=1) == Y_val_test.argmax(dim=1)).sum().item()/len(X_val_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
